{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "9vN8l4-UvgqJ"
      },
      "source": [
        "<div style=\"text-align:center\">\n",
        "    <h1>\n",
        "        Continuous state spaces\n",
        "    </h1>\n",
        "</div>\n",
        "\n",
        "<br>\n",
        "\n",
        "<div style=\"text-align:center\">\n",
        "    In this notebook we will learn how to adapt tabular methods to continuous state spaces. We will do it with two methods:\n",
        "    state aggregation and tile coding.\n",
        "</div>\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Setup code (not important) - Run this cell by pressing \"Shift + Enter\"\n",
        "\n",
        "\n",
        "\n",
        "!pip install -qq gym==0.23.0\n",
        "\n",
        "\n",
        "from typing import Tuple, Dict, Optional, Iterable, Callable\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import torch\n",
        "from matplotlib import animation\n",
        "\n",
        "from IPython.display import HTML\n",
        "\n",
        "import gym\n",
        "from gym import spaces\n",
        "from gym.error import DependencyNotInstalled\n",
        "\n",
        "import pygame\n",
        "from pygame import gfxdraw\n",
        "\n",
        "\n",
        "class Maze(gym.Env):\n",
        "\n",
        "    def __init__(self, exploring_starts: bool = False,\n",
        "                 shaped_rewards: bool = False, size: int = 5) -> None:\n",
        "        super().__init__()\n",
        "        self.exploring_starts = exploring_starts\n",
        "        self.shaped_rewards = shaped_rewards\n",
        "        self.state = (size - 1, size - 1)\n",
        "        self.goal = (size - 1, size - 1)\n",
        "        self.maze = self._create_maze(size=size)\n",
        "        self.distances = self._compute_distances(self.goal, self.maze)\n",
        "        self.action_space = spaces.Discrete(n=4)\n",
        "        self.action_space.action_meanings = {0: 'UP', 1: 'RIGHT', 2: 'DOWN', 3: \"LEFT\"}\n",
        "        self.observation_space = spaces.MultiDiscrete([size, size])\n",
        "\n",
        "        self.screen = None\n",
        "        self.agent_transform = None\n",
        "\n",
        "    def step(self, action: int) -> Tuple[Tuple[int, int], float, bool, Dict]:\n",
        "        reward = self.compute_reward(self.state, action)\n",
        "        self.state = self._get_next_state(self.state, action)\n",
        "        done = self.state == self.goal\n",
        "        info = {}\n",
        "        return self.state, reward, done, info\n",
        "\n",
        "    def reset(self) -> Tuple[int, int]:\n",
        "        if self.exploring_starts:\n",
        "            while self.state == self.goal:\n",
        "                self.state = tuple(self.observation_space.sample())\n",
        "        else:\n",
        "            self.state = (0, 0)\n",
        "        return self.state\n",
        "\n",
        "    def render(self, mode: str = 'human') -> Optional[np.ndarray]:\n",
        "        assert mode in ['human', 'rgb_array']\n",
        "\n",
        "        screen_size = 600\n",
        "        scale = screen_size / 5\n",
        "\n",
        "        if self.screen is None:\n",
        "            pygame.init()\n",
        "            self.screen = pygame.Surface((screen_size, screen_size))\n",
        "\n",
        "        surf = pygame.Surface((screen_size, screen_size))\n",
        "        surf.fill((22, 36, 71))\n",
        "\n",
        "\n",
        "        for row in range(5):\n",
        "            for col in range(5):\n",
        "\n",
        "                state = (row, col)\n",
        "                for next_state in [(row + 1, col), (row - 1, col), (row, col + 1), (row, col - 1)]:\n",
        "                    if next_state not in self.maze[state]:\n",
        "\n",
        "                        # Add the geometry of the edges and walls (i.e. the boundaries between\n",
        "                        # adjacent squares that are not connected).\n",
        "                        row_diff, col_diff = np.subtract(next_state, state)\n",
        "                        left = (col + (col_diff > 0)) * scale - 2 * (col_diff != 0)\n",
        "                        right = ((col + 1) - (col_diff < 0)) * scale + 2 * (col_diff != 0)\n",
        "                        top = (5 - (row + (row_diff > 0))) * scale - 2 * (row_diff != 0)\n",
        "                        bottom = (5 - ((row + 1) - (row_diff < 0))) * scale + 2 * (row_diff != 0)\n",
        "\n",
        "                        gfxdraw.filled_polygon(surf, [(left, bottom), (left, top), (right, top), (right, bottom)], (255, 255, 255))\n",
        "\n",
        "        # Add the geometry of the goal square to the viewer.\n",
        "        left, right, top, bottom = scale * 4 + 10, scale * 5 - 10, scale - 10, 10\n",
        "        gfxdraw.filled_polygon(surf, [(left, bottom), (left, top), (right, top), (right, bottom)], (40, 199, 172))\n",
        "\n",
        "        # Add the geometry of the agent to the viewer.\n",
        "        agent_row = int(screen_size - scale * (self.state[0] + .5))\n",
        "        agent_col = int(scale * (self.state[1] + .5))\n",
        "        gfxdraw.filled_circle(surf, agent_col, agent_row, int(scale * .6 / 2), (228, 63, 90))\n",
        "\n",
        "        surf = pygame.transform.flip(surf, False, True)\n",
        "        self.screen.blit(surf, (0, 0))\n",
        "\n",
        "        return np.transpose(\n",
        "                np.array(pygame.surfarray.pixels3d(self.screen)), axes=(1, 0, 2)\n",
        "            )\n",
        "\n",
        "    def close(self) -> None:\n",
        "        if self.screen is not None:\n",
        "            pygame.display.quit()\n",
        "            pygame.quit()\n",
        "            self.screen = None\n",
        "\n",
        "    def compute_reward(self, state: Tuple[int, int], action: int) -> float:\n",
        "        next_state = self._get_next_state(state, action)\n",
        "        if self.shaped_rewards:\n",
        "            return - (self.distances[next_state] / self.distances.max())\n",
        "        return - float(state != self.goal)\n",
        "\n",
        "    def simulate_step(self, state: Tuple[int, int], action: int):\n",
        "        reward = self.compute_reward(state, action)\n",
        "        next_state = self._get_next_state(state, action)\n",
        "        done = next_state == self.goal\n",
        "        info = {}\n",
        "        return next_state, reward, done, info\n",
        "\n",
        "    def _get_next_state(self, state: Tuple[int, int], action: int) -> Tuple[int, int]:\n",
        "        if action == 0:\n",
        "            next_state = (state[0] - 1, state[1])\n",
        "        elif action == 1:\n",
        "            next_state = (state[0], state[1] + 1)\n",
        "        elif action == 2:\n",
        "            next_state = (state[0] + 1, state[1])\n",
        "        elif action == 3:\n",
        "            next_state = (state[0], state[1] - 1)\n",
        "        else:\n",
        "            raise ValueError(\"Action value not supported:\", action)\n",
        "        if next_state in self.maze[state]:\n",
        "            return next_state\n",
        "        return state\n",
        "\n",
        "    @staticmethod\n",
        "    def _create_maze(size: int) -> Dict[Tuple[int, int], Iterable[Tuple[int, int]]]:\n",
        "        maze = {(row, col): [(row - 1, col), (row + 1, col), (row, col - 1), (row, col + 1)]\n",
        "                for row in range(size) for col in range(size)}\n",
        "\n",
        "        left_edges = [[(row, 0), (row, -1)] for row in range(size)]\n",
        "        right_edges = [[(row, size - 1), (row, size)] for row in range(size)]\n",
        "        upper_edges = [[(0, col), (-1, col)] for col in range(size)]\n",
        "        lower_edges = [[(size - 1, col), (size, col)] for col in range(size)]\n",
        "        walls = [\n",
        "            [(1, 0), (1, 1)], [(2, 0), (2, 1)], [(3, 0), (3, 1)],\n",
        "            [(1, 1), (1, 2)], [(2, 1), (2, 2)], [(3, 1), (3, 2)],\n",
        "            [(3, 1), (4, 1)], [(0, 2), (1, 2)], [(1, 2), (1, 3)],\n",
        "            [(2, 2), (3, 2)], [(2, 3), (3, 3)], [(2, 4), (3, 4)],\n",
        "            [(4, 2), (4, 3)], [(1, 3), (1, 4)], [(2, 3), (2, 4)],\n",
        "        ]\n",
        "\n",
        "        obstacles = upper_edges + lower_edges + left_edges + right_edges + walls\n",
        "\n",
        "        for src, dst in obstacles:\n",
        "            maze[src].remove(dst)\n",
        "\n",
        "            if dst in maze:\n",
        "                maze[dst].remove(src)\n",
        "\n",
        "        return maze\n",
        "\n",
        "    @staticmethod\n",
        "    def _compute_distances(goal: Tuple[int, int],\n",
        "                           maze: Dict[Tuple[int, int], Iterable[Tuple[int, int]]]) -> np.ndarray:\n",
        "        distances = np.full((5, 5), np.inf)\n",
        "        visited = set()\n",
        "        distances[goal] = 0.\n",
        "\n",
        "        while visited != set(maze):\n",
        "            sorted_dst = [(v // 5, v % 5) for v in distances.argsort(axis=None)]\n",
        "            closest = next(x for x in sorted_dst if x not in visited)\n",
        "            visited.add(closest)\n",
        "\n",
        "            for neighbour in maze[closest]:\n",
        "                distances[neighbour] = min(distances[neighbour], distances[closest] + 1)\n",
        "        return distances\n",
        "\n",
        "\n",
        "def plot_policy(probs_or_qvals, frame, action_meanings=None):\n",
        "    if action_meanings is None:\n",
        "        action_meanings = {0: 'U', 1: 'R', 2: 'D', 3: 'L'}\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
        "    max_prob_actions = probs_or_qvals.argmax(axis=-1)\n",
        "    probs_copy = max_prob_actions.copy().astype(object)\n",
        "    for key in action_meanings:\n",
        "        probs_copy[probs_copy == key] = action_meanings[key]\n",
        "    sns.heatmap(max_prob_actions, annot=probs_copy, fmt='', cbar=False, cmap='coolwarm',\n",
        "                annot_kws={'weight': 'bold', 'size': 12}, linewidths=2, ax=axes[0])\n",
        "    axes[1].imshow(frame)\n",
        "    axes[0].axis('off')\n",
        "    axes[1].axis('off')\n",
        "    plt.suptitle(\"Policy\", size=18)\n",
        "    plt.tight_layout()\n",
        "\n",
        "\n",
        "def plot_values(state_values, frame):\n",
        "    f, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
        "    sns.heatmap(state_values, annot=True, fmt=\".2f\", cmap='coolwarm',\n",
        "                annot_kws={'weight': 'bold', 'size': 12}, linewidths=2, ax=axes[0])\n",
        "    axes[1].imshow(frame)\n",
        "    axes[0].axis('off')\n",
        "    axes[1].axis('off')\n",
        "    plt.tight_layout()\n",
        "\n",
        "\n",
        "def display_video(frames):\n",
        "    # Copied from: https://colab.research.google.com/github/deepmind/dm_control/blob/master/tutorial.ipynb\n",
        "    orig_backend = matplotlib.get_backend()\n",
        "    matplotlib.use('Agg')\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
        "    matplotlib.use(orig_backend)\n",
        "    ax.set_axis_off()\n",
        "    ax.set_aspect('equal')\n",
        "    ax.set_position([0, 0, 1, 1])\n",
        "    im = ax.imshow(frames[0])\n",
        "    def update(frame):\n",
        "        im.set_data(frame)\n",
        "        return [im]\n",
        "    anim = animation.FuncAnimation(fig=fig, func=update, frames=frames,\n",
        "                                    interval=50, blit=True, repeat=False)\n",
        "    return HTML(anim.to_html5_video())\n",
        "\n",
        "\n",
        "def test_agent(env, policy, episodes=10):\n",
        "    frames = []\n",
        "    for episode in range(episodes):\n",
        "        state = env.reset()\n",
        "        done = False\n",
        "        frames.append(env.render(mode=\"rgb_array\"))\n",
        "\n",
        "        while not done:\n",
        "            p = policy(state)\n",
        "            if isinstance(p, np.ndarray):\n",
        "                action = np.random.choice(4, p=p)\n",
        "            else:\n",
        "                action = p\n",
        "            next_state, reward, done, extra_info = env.step(action)\n",
        "            img = env.render(mode=\"rgb_array\")\n",
        "            frames.append(img)\n",
        "            state = next_state\n",
        "\n",
        "    return display_video(frames)\n",
        "\n",
        "\n",
        "def plot_action_values(action_values):\n",
        "\n",
        "    text_positions = [\n",
        "        [(0.35, 4.75), (1.35, 4.75), (2.35, 4.75), (3.35, 4.75), (4.35, 4.75),\n",
        "         (0.35, 3.75), (1.35, 3.75), (2.35, 3.75), (3.35, 3.75), (4.35, 3.75),\n",
        "         (0.35, 2.75), (1.35, 2.75), (2.35, 2.75), (3.35, 2.75), (4.35, 2.75),\n",
        "         (0.35, 1.75), (1.35, 1.75), (2.35, 1.75), (3.35, 1.75), (4.35, 1.75),\n",
        "         (0.35, 0.75), (1.35, 0.75), (2.35, 0.75), (3.35, 0.75), (4.35, 0.75)],\n",
        "        [(0.6, 4.45), (1.6, 4.45), (2.6, 4.45), (3.6, 4.45), (4.6, 4.45),\n",
        "         (0.6, 3.45), (1.6, 3.45), (2.6, 3.45), (3.6, 3.45), (4.6, 3.45),\n",
        "         (0.6, 2.45), (1.6, 2.45), (2.6, 2.45), (3.6, 2.45), (4.6, 2.45),\n",
        "         (0.6, 1.45), (1.6, 1.45), (2.6, 1.45), (3.6, 1.45), (4.6, 1.45),\n",
        "         (0.6, 0.45), (1.6, 0.45), (2.6, 0.45), (3.6, 0.45), (4.6, 0.45)],\n",
        "        [(0.35, 4.15), (1.35, 4.15), (2.35, 4.15), (3.35, 4.15), (4.35, 4.15),\n",
        "         (0.35, 3.15), (1.35, 3.15), (2.35, 3.15), (3.35, 3.15), (4.35, 3.15),\n",
        "         (0.35, 2.15), (1.35, 2.15), (2.35, 2.15), (3.35, 2.15), (4.35, 2.15),\n",
        "         (0.35, 1.15), (1.35, 1.15), (2.35, 1.15), (3.35, 1.15), (4.35, 1.15),\n",
        "         (0.35, 0.15), (1.35, 0.15), (2.35, 0.15), (3.35, 0.15), (4.35, 0.15)],\n",
        "        [(0.05, 4.45), (1.05, 4.45), (2.05, 4.45), (3.05, 4.45), (4.05, 4.45),\n",
        "         (0.05, 3.45), (1.05, 3.45), (2.05, 3.45), (3.05, 3.45), (4.05, 3.45),\n",
        "         (0.05, 2.45), (1.05, 2.45), (2.05, 2.45), (3.05, 2.45), (4.05, 2.45),\n",
        "         (0.05, 1.45), (1.05, 1.45), (2.05, 1.45), (3.05, 1.45), (4.05, 1.45),\n",
        "         (0.05, 0.45), (1.05, 0.45), (2.05, 0.45), (3.05, 0.45), (4.05, 0.45)]]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(7, 7))\n",
        "    tripcolor = quatromatrix(action_values, ax=ax,\n",
        "                             triplotkw={\"color\": \"k\", \"lw\": 1}, tripcolorkw={\"cmap\": \"coolwarm\"})\n",
        "    ax.margins(0)\n",
        "    ax.set_aspect(\"equal\")\n",
        "    fig.colorbar(tripcolor)\n",
        "\n",
        "    for j, av in enumerate(text_positions):\n",
        "        for i, (xi, yi) in enumerate(av):\n",
        "            plt.text(xi, yi, round(action_values[:, :, j].flatten()[i], 2), size=8, color=\"w\", weight=\"bold\")\n",
        "\n",
        "    plt.title(\"Action values Q(s,a)\", size=18)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def quatromatrix(action_values, ax=None, triplotkw=None, tripcolorkw=None):\n",
        "    action_values = np.flipud(action_values)\n",
        "    n = 5\n",
        "    m = 5\n",
        "    a = np.array([[0, 0], [0, 1], [.5, .5], [1, 0], [1, 1]])\n",
        "    tr = np.array([[0, 1, 2], [0, 2, 3], [2, 3, 4], [1, 2, 4]])\n",
        "    A = np.zeros((n * m * 5, 2))\n",
        "    Tr = np.zeros((n * m * 4, 3))\n",
        "    for i in range(n):\n",
        "        for j in range(m):\n",
        "            k = i * m + j\n",
        "            A[k * 5:(k + 1) * 5, :] = np.c_[a[:, 0] + j, a[:, 1] + i]\n",
        "            Tr[k * 4:(k + 1) * 4, :] = tr + k * 5\n",
        "    C = np.c_[action_values[:, :, 3].flatten(), action_values[:, :, 2].flatten(),\n",
        "              action_values[:, :, 1].flatten(), action_values[:, :, 0].flatten()].flatten()\n",
        "\n",
        "    ax.triplot(A[:, 0], A[:, 1], Tr, **triplotkw)\n",
        "    tripcolor = ax.tripcolor(A[:, 0], A[:, 1], Tr, facecolors=C, **tripcolorkw)\n",
        "    return tripcolor\n",
        "\n",
        "\n",
        "def seed_everything(env: gym.Env, seed: int = 42) -> None:\n",
        "    env.seed(seed)\n",
        "    env.action_space.seed(seed)\n",
        "    env.observation_space.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.use_deterministic_algorithms(True)\n",
        "\n",
        "\n",
        "def plot_tabular_cost_to_go(action_values, xlabel, ylabel):\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    cost_to_go = -action_values.max(axis=-1)\n",
        "    plt.imshow(cost_to_go, cmap='jet')\n",
        "    plt.title(\"Estimated cost-to-go\", size=24)\n",
        "    plt.xlabel(xlabel, size=18)\n",
        "    plt.ylabel(ylabel, size=18)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.xticks()\n",
        "    plt.colorbar()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_stats(stats):\n",
        "    rows = len(stats)\n",
        "    cols = 1\n",
        "\n",
        "    fig, ax = plt.subplots(rows, cols, figsize=(12, 6))\n",
        "\n",
        "    for i, key in enumerate(stats):\n",
        "        vals = stats[key]\n",
        "        vals = [np.mean(vals[i-10:i+10]) for i in range(10, len(vals)-10)]\n",
        "        if len(stats) > 1:\n",
        "            ax[i].plot(range(len(vals)), vals)\n",
        "            ax[i].set_title(key, size=18)\n",
        "        else:\n",
        "            ax.plot(range(len(vals)), vals)\n",
        "            ax.set_title(key, size=18)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "RH8HXBTBvwBs",
        "cellView": "form",
        "outputId": "da322ba8-3658-4d6b-ac43-4c624fc09527",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/624.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.1/624.4 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m614.4/624.4 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m624.4/624.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a40Bl59vgqL"
      },
      "source": [
        "## Import the necessary software libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ITOgJ74WvgqL"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYUqQBl1vgqM"
      },
      "source": [
        "## Implement state aggregation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3COnudvvgqM"
      },
      "source": [
        "### Create the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Zpo8BQEAvgqM"
      },
      "outputs": [],
      "source": [
        "env = gym.make('MountainCar-v0')\n",
        "seed_everything(env) #have a same result when working at home"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.reset() #array([-0.4452088,  0.       ], dtype=float32) (position of the car, velocity (vận tốc chiếc xe))"
      ],
      "metadata": {
        "id": "akeOQt-IBzK0",
        "outputId": "1f9663c6-e87a-418b-cabf-77176b225341",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.5122243,  0.       ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frame = env.render(mode='rgb_array')\n",
        "plt.imshow(frame);"
      ],
      "metadata": {
        "id": "hi-9_4chCtj-",
        "outputId": "d2e19582-635f-4e15-9178-fe9dc1f7074d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qo3ssx5cvgqM"
      },
      "source": [
        "### Create the state aggregation wrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVjaqy9FvgqM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNAXqTtlvgqN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4cAudZsvgqN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGyKnzn6vgqN"
      },
      "source": [
        "### Compare the original environment to the one with aggregated states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rd_a-ui9vgqN"
      },
      "outputs": [],
      "source": [
        "print(f\"Modified observation space: {saenv.observation_space}, \\n\\\n",
        "Sample state: {saenv.observation_space.sample()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9csRyU1SvgqN"
      },
      "outputs": [],
      "source": [
        "print(f\"Original observation space: {env.observation_space}, \\n\\\n",
        "Sample state: {env.observation_space.sample()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_igeDTqvgqN"
      },
      "source": [
        "### Create the $Q(s,a)$ value table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmmC_IwfvgqN"
      },
      "outputs": [],
      "source": [
        "action_values = np.zeros((20,20, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxEX6ZvGvgqN"
      },
      "source": [
        "### Create the $\\epsilon$-greedy policy: $\\pi(s)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2CSJjIzvgqN"
      },
      "outputs": [],
      "source": [
        "def policy(state, epsilon=0.):\n",
        "    if np.random.random() < epsilon:\n",
        "        return np.random.randint(3)\n",
        "    else:\n",
        "        av = action_values[state]\n",
        "        return np.random.choice(np.flatnonzero(av == av.max()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnZ2AUVmvgqN"
      },
      "source": [
        "### Test the SARSA algorithm on the modified environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jitSZTRRvgqO"
      },
      "outputs": [],
      "source": [
        "def sarsa(action_values, policy, episodes, alpha=0.1, gamma=0.99, epsilon=0.2):\n",
        "    stats = {'Returns': []}\n",
        "    for episode in tqdm(range(1, episodes + 1)):\n",
        "        state = saenv.reset()\n",
        "        action = policy(state, epsilon)\n",
        "        done = False\n",
        "        ep_return = 0\n",
        "        while not done:\n",
        "            next_state, reward, done, _ = saenv.step(action)\n",
        "            next_action = policy(next_state, epsilon)\n",
        "\n",
        "            qsa = action_values[state][action]\n",
        "            next_qsa = action_values[next_state][next_action]\n",
        "            action_values[state][action] = qsa + alpha * (reward + gamma * next_qsa - qsa)\n",
        "            state = next_state\n",
        "            action = next_action\n",
        "            ep_return += reward\n",
        "        stats['Returns'].append(ep_return)\n",
        "    return stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRoh3U-QvgqO"
      },
      "outputs": [],
      "source": [
        "stats = sarsa(action_values, policy, 20000, alpha=0.1, epsilon=0.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RacbxBmZvgqO"
      },
      "outputs": [],
      "source": [
        "plot_stats(stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZmOJxuUvgqO"
      },
      "source": [
        "### Plot the learned policy: $\\pi(s)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57NP8GQRvgqO"
      },
      "outputs": [],
      "source": [
        "plot_policy(action_values, env.render(mode='rgb_array'), \\\n",
        "            action_meanings={0: 'B', 1: 'N', 2: 'F'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nvBZFSgvgqO"
      },
      "source": [
        "### Plot the cost to go: $ - \\max_a \\hat q(s,a|\\theta)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "SUsd_F73vgqO"
      },
      "outputs": [],
      "source": [
        "plot_tabular_cost_to_go(action_values, xlabel=\"Car Position\", ylabel=\"Velocity\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1P7kUmXvgqO"
      },
      "source": [
        "### Test the resulting policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZX89VryvgqO"
      },
      "outputs": [],
      "source": [
        "test_agent(saenv, policy, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W47pYQdCvgqO"
      },
      "source": [
        "<br><br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVg1SvxOvgqO"
      },
      "source": [
        "## Implement Tile Coding\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOggOxgHvgqO"
      },
      "source": [
        "### Create the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YD3C41lgvgqO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbbJcOtCvgqO"
      },
      "source": [
        "### Create the Tile Coding wrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZls8wqNvgqO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zo286x38vgqO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ4JBdNTvgqO"
      },
      "source": [
        "### Compare the original environment to the one with aggregated states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Bs_FL8jvgqO"
      },
      "outputs": [],
      "source": [
        "print(f\"Modified observation space: {tcenv.observation_space}, \\n\\\n",
        "Sample state: {tcenv.reset()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mg7B8yH1vgqO"
      },
      "outputs": [],
      "source": [
        "print(f\"Original observation space: {env.observation_space}, \\n\\\n",
        "Sample state: {env.reset()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hxhy2cXmvgqO"
      },
      "source": [
        "### Create the $Q(s,a)$ value table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y46HsY2TvgqS"
      },
      "outputs": [],
      "source": [
        "action_values = np.zeros((4, 20, 20, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bI9pWIevgqS"
      },
      "source": [
        "### Create the $\\epsilon$-greedy policy: $\\pi(s)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9K2iDRbIvgqS"
      },
      "outputs": [],
      "source": [
        "def policy(state, epsilon=0.):\n",
        "    if np.random.random() < epsilon:\n",
        "        return np.random.randint(3)\n",
        "    else:\n",
        "        av_list = []\n",
        "        for i, idx in enumerate(state):\n",
        "            av = action_values[i][idx]\n",
        "            av_list.append(av)\n",
        "\n",
        "        av = np.mean(av_list, axis=0)\n",
        "        return np.random.choice(np.flatnonzero(av==av.max()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRGnsmKlvgqS"
      },
      "source": [
        "### Test the SARSA algorithm on the modified environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UtvHUrxvgqS"
      },
      "outputs": [],
      "source": [
        "def sarsa(action_values, policy, episodes, alpha=0.1, gamma=0.99, epsilon=0.2):\n",
        "    stats = {'Returns': []}\n",
        "    for episode in tqdm(range(1, episodes + 1)):\n",
        "        state = tcenv.reset()\n",
        "        action = policy(state, epsilon)\n",
        "        done = False\n",
        "        ep_return = 0\n",
        "        while not done:\n",
        "            next_state, reward, done, _ = tcenv.step(action)\n",
        "            next_action = policy(next_state, epsilon)\n",
        "\n",
        "            for i, (idx, next_idx) in enumerate(zip(state, next_state)):\n",
        "                qsa = action_values[i][idx][action]\n",
        "                next_qsa = action_values[i][next_idx][next_action]\n",
        "                action_values[i][idx][action] = qsa + alpha * (reward + gamma * next_qsa - qsa)\n",
        "\n",
        "            state = next_state\n",
        "            action = next_action\n",
        "            ep_return += reward\n",
        "        stats['Returns'].append(ep_return)\n",
        "    return stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MW_884NBvgqS"
      },
      "outputs": [],
      "source": [
        "stats = sarsa(action_values, policy, 20000, alpha=0.1, epsilon=0.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGdpV9TNvgqS"
      },
      "outputs": [],
      "source": [
        "plot_stats(stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_MzBqr2vgqS"
      },
      "source": [
        "### Plot the learned policy: $\\pi(s)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jV_XpCylvgqS"
      },
      "outputs": [],
      "source": [
        "plot_policy(action_values.mean(axis=0), env.render(mode='rgb_array'), \\\n",
        "            action_meanings={0: 'B', 1: 'N', 2: 'F'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_0TY7oovgqT"
      },
      "source": [
        "### Plot the cost to go: $ - \\max_a \\hat q(s,a|\\theta)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3G9nCyMvgqT"
      },
      "outputs": [],
      "source": [
        "plot_tabular_cost_to_go(action_values.mean(axis=0), \\\n",
        "                        xlabel=\"Car Position\", ylabel=\"Velocity\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8z4PLeQvgqT"
      },
      "source": [
        "### Test the resulting policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmopjBSTvgqT"
      },
      "outputs": [],
      "source": [
        "test_agent(tcenv, policy, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_qLNpc0vgqT"
      },
      "source": [
        "## Resources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8lQEV8uvgqT"
      },
      "source": [
        "[[1] Reinforcement Learning: An Introduction. Section 9.5.4: Tile Coding](https://web.stanford.edu/class/psych209/Readings/SuttonBartoIPRLBook2ndEd.pdf)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}